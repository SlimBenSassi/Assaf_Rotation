%% TIME-FREQUENCY LOGISTIC REGRESSION ANALYSIS


%% 1. INITIALIZATION AND LOAD MASTER TABLE

%clear; close all; clc
disp('--- Piloting GLMM Prediction Model ---');

%--- Configuration ---
DEFAULT_PATH = 'C:\Users\ssassi\Desktop\Assaf_Rotation\Data'; % Default folder where your processed data is saved
%example christina data: \\wks3\pr_breska\el-Christina\Backup Copy Christina\PF_Poster\Data\EEG\
% christina eeg trigger list "\\wks3\pr_breska\el-Christina\SxA\SxA_Data\EEGTriggerList.docx"

% --- 1. Use UIGETFILE for Interactive Selection (GUI Dialog) ---
[filename, filepath] = uigetfile({'*.mat','MATLAB Data File (*.mat)' ;'*.*', 'All files (*.*)'},...
                                    'Select Clean Preprocessed SDATA File', DEFAULT_PATH);

if isequal(filename, 0)
    disp('No file selected. Aborting script.');
    return; 
end

master_table_file = fullfile(filepath, filename);

tic

% Load the MasterTable (contains SubjectID, AlphaPower, StimIntensity, SubjectiveOutcome)
load(master_table_file, 'MasterTable');
toc
disp('Master Table loaded successfully.');

% Ensure data types are correct for the GLMM function
MasterTable.SubjectID = categorical(MasterTable.SubjectID);
MasterTable.SubjectiveOutcome = logical(MasterTable.SubjectiveOutcome); 

% Display total N and the first few rows
disp(['Total trials in model: ' num2str(size(MasterTable, 1))]);
head(MasterTable);

%copy in case I need it quickly instead of reloading dataset file
MasterTable_copy = MasterTable;



%% GLOBAL VARIABLES

DO_BASELINE_CORRECTION = true;
Fs = 1024; % Assuming Fs is 1024 Hz
n_channels = 71; %change if needed
PRE_EVENT_SEC = 0.5; % Assumed pre-stimulus window
N_TIME_BINS = 10;
N_FREQ_BINS = 5; % Code not ready for other values yet
alpha_freq_range = [8 12];
time_window_sec = [-0.350 0];
baseline_start_sec = -0.490; % to avoid rounding problems not taking -500ms
baseline_end_sec = -0.400; 



% --- Channels --- %
single_channel_idx = 48; % Cz=48, Oz=29
ROI.Central = {[11, 12, 13, 46, 47, 48 ,49], "Central Cluster"};
ROI.Occipital = {[25, 26, 27, 28, 29, 30, 62, 63, 64], "Occipital Cluster"};
ROI.All = {[1:n_channels], "All Channels"};
ROI.Single = {[single_channel_idx], num2str(single_channel_idx)}; %put electrode of interest idx in here
current_ROI_cell = ROI.Occipital;
currentROI = current_ROI_cell{1};
currentROI_name = current_ROI_cell{2};


%% BASELINE_CORRECTION

tic
if DO_BASELINE_CORRECTION
    for i = 1:height(MasterTable)
        MasterTable.AlphaAmplitude{i} = baseline_correction(MasterTable.AlphaAmplitude{i}, Fs, PRE_EVENT_SEC, baseline_start_sec, baseline_end_sec);
    end
    disp('All single-trial Alpha features are now baseline-normalized (dB).');
end
toc

%% AVERAGE DATA OF ROI (only run this if data file loaded isn't already ROI-averaged)

% 1. Average across the Channel Dimension (Dimension 3)
% Slices the power envelope to the current ROI channels and averages their values.
tic
for i = 1:height(MasterTable)
        MasterTable.AlphaAmplitude{i} = squeeze(mean(MasterTable.AlphaAmplitude{i}(:, :, currentROI), 3));
end
toc
disp('All single-trial Alpha features are now averaged over ROI channels.');

%% Z-SCORING (ASSUMES CHANNELS ALREADY AVERAGED)

tic
MasterTable = zscore_data(MasterTable, Fs, PRE_EVENT_SEC, baseline_start_sec, baseline_end_sec);
toc

disp('All single-trial Alpha Amplitude and StimIntensity data is now Z-scored within condition.');

%% DIFFERENT DATASETS    

% Convert the categorical column to its underlying numeric codes (1, 2, 3)
condition_codes = double(MasterTable.Condition);

% Now use the numerical codes for the comparison logic

% 1. MasterTable_Predictive (Condition < 3: Keep Rhythm and Interval)
MasterTable_Predictive = MasterTable(condition_codes < 3, :);

% 1.a Rhythm
MasterTable_Rhythm = MasterTable(condition_codes == 1, :);

% 1.b Interval
MasterTable_Interval = MasterTable(condition_codes == 2, :);

% 2. MasterTable_Irregular (Condition == 3: Keep Irregular)
MasterTable_Irregular = MasterTable(condition_codes == 3, :);

%% TIME-FREQUENCY REGRESSION MAP

outcome_type = 'Subjective';

tic
[BetaMap, PValueMap, TimeBins, FreqBins] = tf_regression_map(MasterTable_Irregular, Fs, time_window_sec, alpha_freq_range, N_TIME_BINS, N_FREQ_BINS, outcome_type);
toc


%% INTERACTION ANALYSIS

% Here we will take one alpha predictor and not each time-frequency
% combination, choice is informed visually by the heatmap results.

time_pred_bin = [-0.200; -0.100];
freq_pred_bin = [10; 11];

time_zero_sample = round(PRE_EVENT_SEC * Fs); 
pred_start_sample = time_zero_sample + round(time_pred_bin(1) * Fs); 
pred_end_sample = time_zero_sample + round(time_pred_bin(2) * Fs);

all_freqs = [alpha_freq_range(1):alpha_freq_range(2)];
freq_start_sample = find(all_freqs==freq_pred_bin(1));
freq_end_sample = find(all_freqs==freq_pred_bin(2));


% assumes no channel dimension
for i = 1:height(MasterTable)
    MasterTable.AlphaAmplitudeAvg(i) = ...
    squeeze(mean(mean(MasterTable.AlphaAmplitude{i}(pred_start_sample:pred_end_sample, freq_start_sample:freq_end_sample), 1), 2));
end

%% A.1 LINEAR ALPHA SLOPE PER INTENSITY (NO INTERACTION TERM)

data_condition = MasterTable_Interval;
outcome_type = 'Objective';

if strcmp(outcome_type, 'Subjective')
   model_formula1 = 'SubjectiveOutcome ~ AlphaAmplitudeAvg + (1|SubjectID)';
else
   model_formula1 = 'ObjectiveOutcome ~ AlphaAmplitudeAvg + (1|SubjectID)';
end

intensity_levels = unique(data_condition.StimIntensity);
betas_per_intensity = [];


for i = 1:length(intensity_levels)
    
    temp_table = data_condition(data_condition.StimIntensity == intensity_levels(i) , :); 

    glme_alpha_temp = fitglme(temp_table, model_formula1, ...
               'Distribution', 'Binomial', ...
               'Link', 'logit', 'FitMethod','Laplace');

    beta_temp = glme_alpha_temp.Coefficients.Estimate(2);
    
    betas_per_intensity = [betas_per_intensity; beta_temp];

    %disp('Model fitting complete.');
    %disp(glme_alpha_temp.Coefficients);

end

figure('Units', 'normalized', 'Position', [0.1 0.1 0.5 0.5]);

%scatter(intensity_levels, betas_per_intensity);
bar_plot = bar(betas_per_intensity);
hold on;

% Create labels for the X-axis (e.g., 'Bin 1', 'Bin 2', etc.)
labels = arrayfun(@(x) ['Constrast ' num2str(x)], min(intensity_levels):max(intensity_levels), 'UniformOutput', false);

set(gca, 'XTickLabel', labels);
max_abs_beta = max(abs(betas_per_intensity));
ylim([-max_abs_beta-0.01 max_abs_beta]);
%line(xlim, [baseline_accuracy baseline_accuracy], 'Color', 'r', 'LineStyle', '--', 'LineWidth', 1.5); % Chance line

title('Alpha Coefficient Estimate for models trained on each Stimulus Intensity', 'FontSize', 14);
xlabel('Difficulty Level');
ylabel('Alpha Coefficient Estimate');
grid on;

%% A.2 LINEAR ALPHA SLOPE PER INTENSITY (NO INTERACTION TERM)


% Choose model formula
if strcmp(outcome_type, 'Subjective')
    model_formula = 'SubjectiveOutcome ~ AlphaAmplitudeAvg * StimIntensityZ + (1|SubjectID)';
else
    model_formula = 'ObjectiveOutcome ~ AlphaAmplitudeAvg * StimIntensityZ + (1|SubjectID)';
end

% --- 1. Create 10 bins of StimIntensityZ
num_bins = 10;

% Bin StimIntensityZ using quantiles so bins have equal number of samples
data_condition.StimZ_bin = discretize(data_condition.StimIntensityZ, ...
     linspace(min(data_condition.StimIntensityZ), max(data_condition.StimIntensityZ),num_bins+1));

% Compute mean StimIntensityZ per bin
meanZ_per_bin = splitapply(@mean, data_condition.StimIntensityZ, data_condition.StimZ_bin);

%---- 2. Fit one GLME to all data (with interaction!) ----
glme_alpha = fitglme(data_condition, model_formula, ...
           'Distribution','Binomial', ...
           'Link','logit', ...
           'FitMethod','Laplace');

beta0 = glme_alpha.Coefficients.Estimate(1); % intercept
beta1 = glme_alpha.Coefficients.Estimate(3); % Alpha
beta2 = glme_alpha.Coefficients.Estimate(2); % StimZ
beta3 = glme_alpha.Coefficients.Estimate(4); % Alpha × StimZ interaction

% ---- 3. Compute simple slopes: beta_alpha(bin) = beta1 + beta3 * meanStimZ(bin) ----
beta_alpha_per_bin = beta1 + beta3 * meanZ_per_bin;

% ---- 4. Plot ----
figure('Units','normalized','Position',[0.1 0.1 0.5 0.5]);
bar(beta_alpha_per_bin)
hold on

% X labels
labels = arrayfun(@(x) sprintf('Bin %d', x), 1:num_bins, 'UniformOutput', false);
set(gca,'XTickLabel', labels)

max_abs_beta = max(abs(beta_alpha_per_bin));
ylim([-max_abs_beta-0.01, max_abs_beta+0.01])

title('Alpha Slope (β + β_{interaction} × StimZ) across 10 bins')
xlabel('StimIntensityZ Bins')
ylabel('Alpha Simple Slope')
grid on


%% NON-LINEAR INTERACTION MODEL


% Choose model formula
if strcmp(outcome_type, 'Subjective')
    mmodel_formula = ['SubjectiveOutcome ~ AlphaAmplitudeAvg * StimIntensityZ + ' ...
                 'AlphaAmplitudeAvg * StimIntensityZ^2 + (1|SubjectID)'];
else
    model_formula = ['ObjectiveOutcome ~ AlphaAmplitudeAvg * StimIntensityZ + ' ...
                 'AlphaAmplitudeAvg * StimIntensityZ^2 + (1|SubjectID)'];
end
% --- 1. Create 10 bins of StimIntensityZ
num_bins = 10;

% Bin StimIntensityZ using quantiles so bins have equal number of samples
data_condition.StimZ_bin = discretize(data_condition.StimIntensityZ, ...
     linspace(min(data_condition.StimIntensityZ), max(data_condition.StimIntensityZ),num_bins+1));

% Compute mean StimIntensityZ per bin
meanZ_per_bin = splitapply(@mean, data_condition.StimIntensityZ, data_condition.StimZ_bin);

%---- 2. Fit one GLME to all data (with interaction!) ----
glme_alpha = fitglme(data_condition, model_formula, ...
           'Distribution','Binomial', ...
           'Link','logit', ...
           'FitMethod','Laplace');

beta0 = glme_alpha.Coefficients.Estimate(1); % intercept
beta1 = glme_alpha.Coefficients.Estimate(3); % Alpha
beta2 = glme_alpha.Coefficients.Estimate(2); % StimZ
beta3 = glme_alpha.Coefficients.Estimate(4); % Alpha × StimZ interaction
beta4 = glme_alpha.Coefficients.Estimate(6); % Alpha × StimZ^2 interaction

disp(glme_alpha.Coefficients)

% ---- 3. Compute simple slopes: beta_alpha(bin) = beta1 + beta3 * meanStimZ(bin) ----
beta_alpha_per_bin2 = beta1 + beta3 * meanZ_per_bin + beta4 * meanZ_per_bin * 2;

% ---- 4. Plot ----
figure('Units','normalized','Position',[0.1 0.1 0.5 0.5]);
bar(beta_alpha_per_bin2);
hold on

% X labels
labels = arrayfun(@(x) sprintf('Bin %d', x), 1:num_bins, 'UniformOutput', false);
set(gca,'XTickLabel', labels)

max_abs_beta = max(abs(beta_alpha_per_bin2));
ylim([-max_abs_beta-0.01, max_abs_beta+0.01])

title('Alpha Slope (β + β_{interaction} × StimZ) across 10 bins')
xlabel('StimIntensityZ Bins')
ylabel('Alpha Simple Slope')
grid on




%% A.4 Comparing Linear Interaction to true interaction

%PLOT GROUPED BETA COEFFICIENTS (Comparing Model Effects)

% --- 1. Create the Grouped Matrix ---
% The matrix must be [N_Bins x N_Models]
beta_comparison_matrix = [betas_per_intensity, beta_alpha_per_bin, beta_alpha   ];

% --- 2. Create the Figure and Bar Plot ---
figure('Units', 'normalized', 'Position', [0.1 0.1 0.6 0.6]);

% Plot the matrix. MATLAB automatically groups the bars by row (intensity level).
hBar = bar(beta_comparison_matrix);
hold on;

% --- 3. Add Zero Line (Crucial Reference) ---
line(xlim, [0 0], 'Color', 'k', 'LineStyle', ':', 'LineWidth', 1.5);

% --- 4. Aesthetics and Labels ---
% Use the raw intensity levels (e.g., 1 to 7) for X-axis labels
intensity_labels = arrayfun(@(x) ['Level ' num2str(x)], intensity_levels, 'UniformOutput', false);

set(gca, 'XTickLabel', intensity_labels);
title('Predictive Power (Beta) by Intensity: Simple vs. Complex Model', 'FontSize', 14);
xlabel('Stimulus Intensity Level (Bins)');
ylabel('Alpha Power Beta Coefficient (Log-Odds)');
legend({'Simple Model (\alpha Only)', 'Complex Model (\alpha at Specific Intensity)'}, 'Location', 'NorthWest');
grid on;
hold off;


%% SHORT EXPLORATIION OF CALIBRATION

% 1.  EMPIRICAL CONFUSION MATRIX (Observed vs. Reality)

% --- Configuration ---
% Note: We assume that TRUE (1) means "Correct Tilt Identified" (Objective Positive) 
% and TRUE (1) means "Reported Seen" (Subjective Positive).

objective_outcome = double(MasterTable.ObjectiveOutcome); % Actual result (0 or 1)
subjective_outcome = double(MasterTable.SubjectiveOutcome); % Subject's report (0 or 1)

% --- 1. Calculate the Four Outcomes ---

% True Positives (TP): Subjective SEEN (1) AND Objective CORRECT (1)
TP = sum(objective_outcome == 1 & subjective_outcome == 1);

% True Negatives (TN): Subjective UNSEEN (0) AND Objective INCORRECT (0)
TN = sum(objective_outcome == 0 & subjective_outcome == 0);

% False Positives (FP): Subjective SEEN (1) BUT Objective INCORRECT (0)
% Subject reported seeing it, but made an incorrect objective judgment. (Overconfidence)
FP = sum(objective_outcome == 0 & subjective_outcome == 1);

% False Negatives (FN): Subjective UNSEEN (0) BUT Objective CORRECT (1)
% Subject missed seeing it, but was objectively correct. (Unconscious processing)
FN = sum(objective_outcome == 1 & subjective_outcome == 0);


% --- 2. Display the Results (Averaged Across Participants) ---
N_total = TP + TN + FP + FN;

disp(' ');
disp('--- EMPIRICAL CONFUSION MATRIX (Participant Report vs. Reality) ---');
disp(['Total Trials: ' num2str(N_total)]);
disp(' ');
disp('RESULTING CATEGORIES:');
disp(['TP (Seen & Correct): ' num2str(TP/N_total * 100, 3) '%']);
disp(['TN (Unseen and Incorrect Rejected): ' num2str(TN/N_total * 100, 3) '%']);
disp(['FP (False Alarm/Overconfidence): ' num2str(FP/N_total * 100, 3) '%']);
disp(['FN (Unconscious Processing or Guessing): ' num2str(FN/N_total * 100, 3) '%']);
disp('------------------------------------------');
